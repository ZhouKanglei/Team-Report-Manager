The primary contribution of this work lies in its ability to preserve the full resolution of foreground objects by integrating instance segmentation. This enhancement greatly improves the user experience of foveated rendering, where visual cues outside the foveated region are often overlooked, leading to a negative impact on task performance. The main concern raised is that the method employed in the paper is straightforward and lacks thorough exploration. Furthermore, in comparison to the previous work [36], the contribution of this paper is a little limited. The following comments and suggestions are provided:

\- Motivation: While maintaining the full resolution of foreground objects improves the user experience, it introduces additional transmission and computational costs. Furthermore, in scenes with numerous objects, the complexity of this approach is magnified, given that objects located outside the foveated region are rarely fixated upon. (1) To address these challenges, it would be beneficial to expand the discussion by exploring potential solutions or mitigations for the increased burden of transmission and computation, particularly in complex scenes. (2) Additionally, investigating techniques to optimize the rendering of objects outside the foveated region could contribute to achieving a more balanced approach.

\- Methodology: The use of an approximation for the retinal region in foveated sampling results in abrupt transitions within the foveated region, as demonstrated in the supporting video, negatively impacting the user experience. Instead, considering the adoption of a widely used method (e.g., https://doi.org/10.2312/evs.20191172) with a Gaussian distribution that gradually decreases from the center towards the periphery would be advisable. This model can be implemented through offline computations, avoiding an increase in computational cost while enhancing the user experience.

\- Experiments: The experimental results indicate that users experienced longer task completion times and increased failure rates in the RF setting. (1) However, further discussion and explanation regarding these results, as well as assumptions about the experimental context's influence on user task performance, are warranted. (2) Furthermore, it should be acknowledged that for objects with simpler backgrounds, the proposed method appears to be nearly equivalent to traditional rendering approaches. Additionally, the sparse nature of the point cloud background captured by the depth camera may minimize interference with user task performance. (3) Considering the influence of factors such as object size and other attributes on user task performance and conducting additional investigations in these areas would provide valuable insights, strengthening the overall findings and conclusions of the paper.
